---
title: "Knn"
author: "Rafael A. Irizarry"
date: "`r lubridate::today()`"
output:
  ioslides_presentation:
    fig_caption: no
    fig_height: 5
    fig_width: 7
    out_width: "70%"
  beamer_presentation: default
  slidy_presentation: default
---

```{r setup, include=FALSE}
library(tidyverse)
library(dslabs)
library(gridExtra)
library(ggthemes)
ds_theme_set()
options(digits = 3)
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE,
  out.width = "70%",
  fig.align = "center",
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

img_path <- "img"
```


```{r, echo=FALSE, warning=FALSE, message=FALSE} 
set.seed(2008) 
library(tidyverse) 
library(dslabs) 
library(caret)
data("mnist_27") 
## We use this function to plot the estimated conditional probabilities 
plot_cond_prob <- function(p_hat=NULL){ 
  tmp <- mnist_27$true_p 
  if(!is.null(p_hat)){ 
    tmp <- mutate(tmp, p=p_hat) 
  } 
  tmp |> ggplot(aes(x_1, x_2, z=p, fill=p)) + 
  geom_raster(show.legend = FALSE) + 
  scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) + 
  stat_contour(breaks=c(0.5),color="black") 
} 
``` 


## k-nearest neighbors

- We previously introduced the kNN algorithm  and demonstrated how we use cross validation to pick $k$.

- Here we quickly review how we fit a kNN model using the __caret__ package.

- We introduced the following code to fit a kNN model:

```{r} 
train_knn <- train(y ~ ., method = "knn",  
                   data = mnist_27$train, 
                   tuneGrid = data.frame(k = seq(9, 71, 2))) 
``` 



## k-nearest neighbors

- We saw that the parameter that maximized the estimated accuracy was:

```{r} 
train_knn$bestTune 
``` 

## k-nearest neighbors

- This model improves the accuracy over regression and logistic regression:

```{r} 
confusionMatrix(predict(train_knn, mnist_27$test, type = "raw"), 
                mnist_27$test$y)$overall["Accuracy"] 
``` 

- A plot of the estimated conditional probability shows that the kNN estimate is flexible enough and does indeed capture the shape of the true conditional probability.



## k-nearest neighbors

```{r best-knn-fit, echo=FALSE, out.width="100%"} 
p1 <- plot_cond_prob() + ggtitle("True conditional probability") 
p2 <- plot_cond_prob(predict(train_knn, newdata = mnist_27$true_p, type = "prob")[,2]) + 
  ggtitle("kNN") 
grid.arrange(p2, p1, nrow=1) 
``` 



